m <- matrix(nrow = 3, ncol = 3)
m <- matrix(nrow = 3, ncol = 3)
m <- matrix(nrow = 3, ncol = 3)
print(m)
?matrix
m <- matrix(nrow = 3, ncol = 3)
print(m)
?matrix
m <- matrix(rbind(
c(0,0,0)
c(0,0,0)
?matrix
m <- matrix(rbind(
c(0,0,0),
c(0,0,0),
c(0,0,0)
))
print(m)
?matrix
m <- matrix(cbind(
c(0,0,0),
c(0,0,0),
c(0,0,0)
))
print(m)
?matrix
m <- matrix(0, 3,3)
print(m)
m <- matrix(0, 3,3, dimnames = list(c('A','B','C'), c('A','B','C')))
print(m)
elegans_network <- data(elegans, package = "SNA4DSData")
summary(elegans_network)
plot(elegans_network)
data(elegans, package = "SNA4DSData")
plot(data(elegans, package = "SNA4DSData"))
help(package = 'igraph')
class(network)
network <- data(elegans, package = "SNA4DSData"))
network <- data(elegans, package = "SNA4DSData")
print(class(network))
print(network)
remotes::install_github("SNAnalyst/SNA4DS", dependencies = TRUE)
remotes::install_github("SNAnalyst/SNA4DSData", dependencies = TRUE)
network <- data(elegans, package = "SNA4DSData")
help(package = 'igraph')
print(network)
class(network)
SNA4DS::SNA4DS_tutorials()
q()
igraph::as.undirected(dara)
igraph::as.undirected(data)
data <- data(elegans, package = "SNA4DSData")
help(package = 'igraph')
igraph::as.undirected(data)
igraph::as.data_frame(data)
class(elegans)
source("C:/Gergo-mappa/projects/programming/projects/jads/sna4ds/homeplay_1.R", echo=TRUE)
help(package='igraph')
igraph::dyad_census(elegans)
igraph::reciprocity(elegans)
network <- intergraph::asNetwork(elegans)
class(network)
help(package='sna')
sna::dyad.census(network)
sna::grecip(network, measure = "edgewise")
SNA4DS::SNA4DS_tutorials()
`remotes::install_github("SNAnalyst/SNA4DS", dependencies = TRUE)`
`remotes::install_github("SNAnalyst/SNA4DSData", dependencies = TRUE)`
remotes::install_github("SNAnalyst/SNA4DS", dependencies = TRUE)
SNA4DS::SNA4DS_tutorials()
SNA4DS::open_SNA4DS_vignettes()
data(blososphere, package="SNA4DSData")
remotes::install_github("SNAnalyst/SNA4DSData", dependencies = TRUE)
data(blososphere, package = "SNA4DSData")
data(blogosphere, package = "SNA4DSData")
igraph::which_loop(blogosphere)
loops <- igraph::which_loop(blogosphere)
TRUE in loops
TRUE %in% loops
simple_blogosphere <- igraph::without_loops(blogosphere)
simple_blogosphere <- igraph::simplify(blogosphere, remove.loops = TRUE)
loops_new <- igraph::which_loop(simple_blogosphere)
TRUE %in% loops_new
igraph::mean_distance(simple_blogosphere)
igraph::diameter(simple_blogosphere)
igraph::dyad.census(simple_blogosphere)
igraph::reciprocity(simple_blogosphere)
igraph::transitivity(simple_blogosphere)
igraph::edge_density(simple_blogosphere)
igraph::cluster_walktrap(simple_blogosphere)
?igraph
help(package='igraph')
for (vertice in igraph::V(simple_blogosphere)){
if ( igraph::degree(simple_blogosphere, v = vertice ) == 0){
simple_blogosphere <- igraph::delete.vertices(simple_blogosphere, vertice)
}
}
isolated <- which( igraph::degree(simple_blogosphere) == 0)
connected_blogosphere <- igraph::delete.vertices(simple_blogosphere, isolated)
igraph::cluster_walktrap(connected_blogosphere)
remotes::install_github("SNAnalyst/bootcamp_2021", dependencies=true)
remotes::install_github("SNAnalyst/bootcamp_2021", dependencies=True)
remotes::install_github("SNAnalyst/bootcamp_2021", dependencies=TRUE)
bootcamp2021::bootcamp2021_tutorials()
exit
data(centrality, package = "bootcamp21")
print(descriptives(centrality))
print(bootcamp2021::descriptives(centrality))
bootcamp2021::descriptives(centrality)
data(centrality, package = "bootcamp2021")
bootcamp2021::descriptives(centrality)
mod_1 <- lm(friendship ~ race + gender + age, data = centrality)
summary(mod_1)
bootcamp2021::betterpairs(centrality)
outliertree::outlier.tree(centrality)
mod_2 <- lm(friendship ~ conscientiousness + extraversion + neuroticism + agreeableness + openness_experience)
mod_2 <- lm(friendship ~ conscientiousness + extraversion + neuroticism + agreeableness + openness_experience, data = centrality)
summary(mod_3)
summary(mod_2)
lm(friendship ~ conscientiousness + extraversion + neuroticism + agreeableness + openness_experience + activity_preference, data = centrality)
summary(mod_3)
mod_3 <- lm(friendship ~ conscientiousness + extraversion + neuroticism + agreeableness + openness_experience + activity_preference, data = centrality)
summary(mod_3)
plot(mod_1)
plot(mod_1)
plot(mod_2)
plot(mod_2)
plot(mod_2)
plot(mod_3)
remotes::install_github("SNAnalyst/bootcamp_2021", dependencies = TRUE, force = TRUE)
bootcamp2021::bootcamp2021_tutorials()
bootcamp2021::bootcamp2021_tutorials()
data(dozen, package = "bootcamp2021")
print(dozen$three)
print(dozen$three)
print(dozen$three)
for ( i in range(1,12)) {
print(apply(dozen[[i]], 2, mean))
}
?rnage
?range
for ( i in sequence(1,12)) {
print(apply(dozen[[i]], 2, mean))
}
for ( i in sequence(1,12)) {
print(i)
print(apply(dozen[[i]], 2, mean))
}
for ( i in sequence(1,12)) {
l = c()
append(l, c(i, apply(dozen[[i]], 2, mean)))
}
print(l)
l = c()
for ( i in sequence(1,12)) {
append(l, c(i, apply(dozen[[i]], 2, mean)))
}
print(l)
for ( i in sequence(1,12)) {
l <- c(l, c(i, apply(dozen[[i]], 2, mean)))
}
print(l)
?sequnece
?sequence
for ( i in seq(from = 1, to = 12, by = 1)) {
l <- c(l, c(i, apply(dozen[[i]], 2, mean)))
}
print(l)
for ( i in seq(from = 1, to = 12, by = 1)) {
plot(x = dozen[[i]]$x, y = dozen[[i]]$y,
main = str(i),
pch = 16,
col = "blue")
abline(reg = lm(sleep$non_dreaming ~ sleep$dreaming), col = "red", lty = "dashed")
text(6.5, 15.3, label = "OLS", col = "red")
}
lapply(dozen, apply, 2, plot(
main = str(i),
pch = 16,
col = "blue"))
?cor
lapply(dozen, apply, 2, plot
lapply(dozen, apply, 2, plot)
(dozen, apply, 2, plot)
lapply(dozen, apply, 2, plot)
for ( i in seq(from = 1, to = 12, by = 1)) {
cor(x = dozen[[i]]$x, dozen[[i]]$y)
}
l = c()
for ( i in seq(from = 1, to = 12, by = 1)) {
l <- c(l, c(i, cor(x = dozen[[i]]$x, dozen[[i]]$y)))
}
print(l)
l = c()
for ( i in seq(from = 1, to = 12, by = 1)) {
l <- c(l, c(i, cor(x = dozen[[i]]$x, dozen[[i]]$y), '####'))
}
(l)
data(loans, package = 'bootcamp2021')
bootcamp2021::descriptives(loans$state)
bootcamp2021::descriptives(loans$debt_to_income)
SNA4DS::SNA4DS_tutorials()
library(dplyr)
games_data <- read.csv('./data/clean_games_data.csv')
dummy <- head(games_data, n=5)
get_word_freq <- function(dataframe, n = 25) {
word_list <- dataframe %>%
tidytext::unnest_tokens(word, clean_text)
freq_list <- word_list %>%
dplyr::count(word, sort = TRUE)
return(c(freq_list[1:n,1]))
}
summary(dummy)
stm_data <- dummy[c('clean_text', 'location', 'Category', 'launch_date')]
processed <- stm::textProcessor(stm_data$clean_text, metadata = stm_data, lowercase = FALSE, removepunctuation = FALSE, stem=FALSE, sparselevel = 0.98, customstopwords = get_word_freq(stm_data))
stm_data <- dummy[c('clean_text', 'location', 'Category', 'launch_date')]
dummy <- head(games_data, n=5)
games_data <- read.csv('./data/clean_games_data.csv')
# setting the working directory to my local computer
setwd('C:/Gergo-mappa/projects/programming/projects/jads/sbm/jads_2021_g9_sbm')
library(dplyr)
games_data <- read.csv('./data/clean_games_data.csv')
dummy <- head(games_data, n=5)
get_word_freq <- function(dataframe, n = 25) {
word_list <- dataframe %>%
tidytext::unnest_tokens(word, clean_text)
freq_list <- word_list %>%
dplyr::count(word, sort = TRUE)
return(c(freq_list[1:n,1]))
}
summary(dummy)
stm_data <- dummy[c('clean_text', 'location', 'Category', 'launch_date')]
processed <- stm::textProcessor(stm_data$clean_text, metadata = stm_data, lowercase = FALSE, removepunctuation = FALSE, stem=FALSE, sparselevel = 0.98, customstopwords = get_word_freq(stm_data))
out <- stm::prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 25, upper.thresh = 2800)
games_data <- read.csv('./data/clean_games_data.csv')
stm_data <- games_data[c('clean_text', 'location', 'Category', 'launch_date')]
processed <- stm::textProcessor(stm_data$clean_text, metadata = stm_data, lowercase = FALSE, removepunctuation = FALSE, stem=FALSE, sparselevel = 0.98, customstopwords = get_word_freq(stm_data))
processed <- stm::textProcessor(stm_data$clean_text, metadata = stm_data, lowercase = FALSE, removepunctuation = FALSE, stem=FALSE, sparselevel = 0.997, customstopwords = get_word_freq(stm_data))
out <- stm::prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 25, upper.thresh = 2800)
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
stm::plotRemoved(processed$documents, lower.thresh = seq(1, 350, by = 50))
out <- stm::prepDocuments(processed$documents, processed$vocab, processed$meta, lower.thresh = 100, upper.thresh = 2800)
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
docs <- out$documents
games_test_fit <- stm::stm(documents = out$documents, vocab = out$vocab, K = 20, prevalence =~ location + Category + launch_date, max.em.its = 75, data = out$meta, init.type = "Spectral")

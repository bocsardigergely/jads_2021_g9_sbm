{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../data/all_project_week_19_32.csv')\n",
    "cols = ['project_slug', 'Category', 'Location', 'Goal_USD', 'Pledge_USD', 'Number_Backers', 'Creator_nb_projects','Project_Community_top_countries','Project_description', 'Deadline', 'Launched_at' ]\n",
    "raw_df = raw_df[cols]\n",
    "raw_df = raw_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering projects that are still running when the data collection happened (2019 aug. 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earliest launch date:  2009-05-06 16:20:07\n",
      "earliest deadline:  2009-06-24 22:26:00\n",
      "latest launch date:  2019-07-30 10:03:18\n",
      "latest deadline:  2019-09-28 08:11:41\n"
     ]
    }
   ],
   "source": [
    "# getting rid on unix timestamps\n",
    "raw_df['end_date'] = pd.to_datetime(raw_df['Deadline'], unit='s', origin='unix')\n",
    "raw_df['launch_date'] = pd.to_datetime(raw_df['Launched_at'], unit='s', origin='unix')\n",
    "\n",
    "# Exploring how the launch- and end-dates look like in the dataset\n",
    "print('earliest launch date: ', raw_df['launch_date'].min())\n",
    "print('earliest deadline: ', raw_df['end_date'].min())\n",
    "print('latest launch date: ', raw_df['launch_date'].max())\n",
    "print('latest deadline: ', raw_df['end_date'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_slug', 'Category', 'Location', 'Goal_USD', 'Pledge_USD',\n",
       "       'Number_Backers', 'Creator_nb_projects',\n",
       "       'Project_Community_top_countries', 'Project_description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering on date of collection\n",
    "cutoff_date = pd.Timestamp(year=2019, month=8, day=11, hour=0)\n",
    "raw_df = raw_df[ raw_df['end_date'] < cutoff_date ]\n",
    "raw_df = raw_df.drop(columns=['Deadline', 'Launched_at', 'launch_date', 'end_date'])\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating target variable and adjusting other attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gettint the top countries by backers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|United States:57 backers|Australia:1 backer|Singapore:1 backer|United Kingdom:1 backer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Project_Community_top_countries'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_country(text):\n",
    "    z = re.search(r'(?<=\\|)(.*?)(?=\\:)', text)\n",
    "    if z is not None:\n",
    "        return z.group()\n",
    "    else: return ''\n",
    "get_top_country('|United States:57 backers|Australia:1 backer|Singapore:1 backer|United Kingdom:1 backer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    United States\n",
       "1    United States\n",
       "2    United States\n",
       "3    United States\n",
       "4    United States\n",
       "Name: top_country, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the top country to use as exo variable for STM\n",
    "raw_df['top_country'] = raw_df.apply( lambda row: get_top_country(row['Project_Community_top_countries']), axis=1)\n",
    "raw_df['top_country'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the percentage of amount actually pledged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing dataset up on meta-categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining meta-categories according to kickstarter standards\n",
    "art_meta = ['Art', 'Ceramics', 'Conceptual Art', 'Digital Art', 'Illustration', 'Installations', 'Mixed Media', 'Painting', 'Performance Art', 'Public Art', 'Sculpture', 'Social Practice', 'Textiles', 'Video Art']\n",
    "comics_meta = ['Comics', 'Comic Books', 'Graphic Novels', 'Webcomics']\n",
    "crafts_meta = ['Crafts', 'Candles', 'Crochet', 'DIY', 'Embroidery', 'Glass', 'Knitting', 'Pottery', 'Printing', 'Quilts', 'Stationery', 'Taxidermy', 'Weaving', 'Woodworking']\n",
    "dance_meta = ['Dance', 'Performances', 'Residencies', 'Workshops']\n",
    "design_meta = ['Design', 'Architecture', 'Civic Design', 'Graphic Design', 'Interactive Design', 'Product Design', 'Toys', 'Typography']\n",
    "fashion_meta =['Fashion', 'Accessories', 'Apparel', 'Childrenswear', 'Couture', 'Footwear', 'Jewelry', 'Pet Fashion', 'Ready-to-wear']\n",
    "film_meta = ['Film', 'Film &amp; Video', 'Action', 'Animation', 'Comedy', 'Documentary', 'Drama', 'Experimental', 'Family', 'Fantasy', 'Festivals', 'Horror', 'Movie Theaters', 'Music Videos', 'Narrative Film', 'Romance', 'Science Fiction', 'Shorts', 'Television', 'Thrillers', 'Webseries']\n",
    "food_meta = ['Food', 'Bacon', 'Community Gardens', 'Cookbooks', 'Drinks', 'Farms', 'Food Trucks', 'Food Trucks', 'Restaurants', 'Small Batch', 'Spaces', 'Vegan']\n",
    "games_meta = ['Games', 'Gaming Hardware', 'Live Games', 'Mobile Games', 'Playing Cards', 'Puzzles', 'Tabletop Games', 'Video Games']\n",
    "journalism_meta = ['Journalism', 'Audio', 'Photo', 'Print', 'Video', 'Web']\n",
    "music_meta = ['Music', 'Blues', 'Chiptune', 'Classical Music', 'Comedy', 'Country &amp; Folk', 'Electronic Music', 'Faith', 'Hip-Hop', 'Indie Rock', 'Jazz', 'Kids', 'Latin', 'Metal', 'Pop', 'Punk', 'R&amp;B', 'Rock', 'World Music']\n",
    "photography_meta = ['Photography', 'Animals', 'Fine Art', 'Nature', 'People', 'Photobooks', 'Places']\n",
    "publishing_meta = ['Publishing', 'Academic', 'Art Books', 'Calendars', 'Children&#39;s Books', 'Comedy', 'Fiction', 'Letterpress', 'Literary Journals', 'Literary Spaces', 'Nonfiction', 'Periodicals', 'Poetry', 'Radio &amp; Podcasts', 'Translations', 'Young Adult', 'Zines']\n",
    "technology_meta = ['Technology', '3D Printing', 'Apps', 'Camera Equipment', 'DIY Electronics', 'Fabrication Tools', 'Flight', 'Gadgets', 'Hardware', 'Makerspaces', 'Robots', 'Software', 'Sound', 'Space Exploration', 'Wearables', 'Web']\n",
    "theater_meta = ['Theater','Comedy', 'Experimental', 'Festivals', 'Immersive', 'Musical', 'Plays']\n",
    "\n",
    "meta_categories = [art_meta, comics_meta, crafts_meta, dance_meta, design_meta, fashion_meta, film_meta, food_meta, games_meta, journalism_meta, music_meta, photography_meta, publishing_meta, technology_meta, theater_meta]\n",
    "cat_df_dict = {}\n",
    "for category in meta_categories:\n",
    "  df_1 = raw_df[raw_df['Category'].isin(category)]\n",
    "  cat_df_dict.update( {str(category[0]): df_1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art category has 8916 rows\n",
      "Comics category has 1925 rows\n",
      "Crafts category has 1728 rows\n",
      "Dance category has 1682 rows\n",
      "Design category has 3588 rows\n",
      "Fashion category has 2112 rows\n",
      "Film category has 8824 rows\n",
      "Food category has 1761 rows\n",
      "Games category has 5165 rows\n",
      "Journalism category has 1011 rows\n",
      "Music category has 9651 rows\n",
      "Photography category has 1777 rows\n",
      "Publishing category has 6677 rows\n",
      "Technology category has 4089 rows\n",
      "Theater category has 1707 rows\n"
     ]
    }
   ],
   "source": [
    "# exploring category numbers\n",
    "for key in cat_df_dict:\n",
    "  print(key + ' category has ' + str(len(cat_df_dict[key])) + ' rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling dataset\n",
    "According to [statista.com](https://www.statista.com/statistics/222455/amount-of-dollars-pledged-per-category-on-kickstarter/), the three most funded categories were *Games*, *Design*, and *Technology*, so we will focus our efforts on these. We will test descriptive stats in R to figure out the best subsampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = cat_df_dict['Games']\n",
    "games_df.to_csv('../data/raw_games_data.csv')\n",
    "design_df = cat_df_dict['Design']\n",
    "design_df.to_csv('../data/raw_design_data.csv')\n",
    "tech_df = cat_df_dict['Technology']\n",
    "tech_df.to_csv('../data/raw_tech_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "\n",
    "The preprocessing will be done using the following function but we run it on a vm to make it faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    if isinstance(text, str):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = text.strip()\n",
    "        result = \"\"\n",
    "        punctless = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "        lowercase = punctless.lower()\n",
    "        words_list = lowercase.split()\n",
    "        words_list =  [ lemmatizer.lemmatize(word) for word in words_list if not word in set(stopwords.words('english')) ]\n",
    "        for word in words_list:\n",
    "            result += \" \" + word.strip()\n",
    "        return result\n",
    "    else: return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d21e30d667f5e24803d3c5fbd4b8ec31db55c536dc2390ac68f528c86e0b6db0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('jads-r5c3IsT5': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
